[
  {
    "path": "posts/2022-08-12-putting-the-fun-in-funneljoin/",
    "title": "Putting the fun in `funneljoin`",
    "description": "An introduction to, an example of, and my (lazy) journey to discovering the `funneljoin` package [10 min read]",
    "author": [
      {
        "name": "Derek Beaton",
        "url": "https://twitter.com/derek__beaton"
      }
    ],
    "date": "2022-08-12",
    "categories": [
      "language-R",
      "project-chartwatch",
      "post-miscellaneous",
      "funneljoin"
    ],
    "contents": "\n\nContents\nMy lazy journey to discovery\nA quick view of the data\nA look at the data\nWhat we want and the behavior we’d expect\n\nA journey to find and a journey through funneljoin\nMy first failure\nMy second failure\nA third successful attempt\n\nConclusions\n\nMy lazy journey to discovery\nA while back, I was helping1 out on one of our new projects: an expansion of CHARTWatch to new units. To learn a bit more about CHARTWatch you should read (Verma et al. 2021) that explains how to get models in the clinical environment and (Pou-Prom et al., n.d.) on all the technical parts required.\nWe were doing some data exploration for the project and we had a fairly straight forward question to answer: What is the first event after a procedure for a patient?\nWith that question, I dove into the data files we had started to get a feel for what to do2. I had a few files to work with, lots of timestamps all over the place, and knew I had some sort of join type problem. I tried—and failed with—many variations of joins (e.g., fuzzyjoin) and even trying to get what was needed in more manual3 ways. One thought kept ringing in my head: “someone must have solved this problem.” So at that point I spent a few half days4 searching. Many fruitless paths later and on the verge of the more manual5 approaches I finally found what I was looking for: funneljoin.\nThough funneljoin was what I was looking for, my use of it was also a journey through multiple mistakes and misunderstandings all of which are my own6. But I eventually got exactly what I wanted: a straightforward way to join some data and find very specific events that occur after other events.\nA quick view of the data\nLet’s start out by taking a look at the data. That’ll give us a better sense of the problem and the behavior we’re expecting. We’re going to be working with a tiny example of what the real data could look like. These fake data have been created from real data and then we used uuid, dplyr::group_by, lubridate and some good old fashioned randomization to make it fake.\nWe have two data files which look a lot like our real data:\nALL_ADT_EVENTS.csv: A file that contains all the Admit-Discharge-Transfer (ADT) events for patients while they are in the hospital, and\nSPECIFIC_PROCEDURES.csv: which contains a very specific set of procedures while in the hospital.\nIt’s very worth noting that all the events in SPECIFIC_PROCEDURES are in ALL_ADT_EVENTS. These are separate for a few reasons including (but certainly not limited to): it’s easier to work with when we want to know only about the procedures, and things like procedures can (and are) pulled from separate pipelines more specific than ADT pipelines.\nA look at the data\nLet’s start out by taking a look at some of the ADT file and a few (preselected) rows to highlight these data. And while we’re at it, we’ll see the code, too!\n\n\nlibrary(here)       ## for here::here() and referencing files from this .RProj\nlibrary(dplyr)      ## for some processing and those fancy pipes\nlibrary(kableExtra) ## for some extra fancy looking tables\nlibrary(rmarkdown)  ## for some even more extra fancy tables\n\nADT_FILE_PATH <- here::here(\"_posts\",\"2022-08-12-putting-the-fun-in-funneljoin\", \"ALL_ADT_EVENTS.csv\")\nADT_EVENTS <- read.csv(ADT_FILE_PATH, \n                        stringsAsFactors = FALSE)\n\nADT_EVENTS %>%\n  slice( c(1, 2, 3, 12, 13, 16, 20, 21) ) %>%\n  kableExtra::kbl() %>%\n  kableExtra::kable_styling() \n\n\n\nENCOUNTER_NUM_ANONYMIZED\n\n\nEVENT_TS_FUZZED\n\n\nFROM_SERVICE\n\n\nTO_SERVICE\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-05-10 06:08:10\n\n\nNA\n\n\nED TRIAGE\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-05-10 06:13:24\n\n\nED TRIAGE\n\n\nED TRAUMA\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-05-10 06:54:10\n\n\nED TRAUMA\n\n\nINTENSIVE CARE TRAUMA\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-13 11:32:48\n\n\nINTENSIVE CARE TRAUMA\n\n\nINTENSIVE CARE TRAUMA\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-18 19:53:13\n\n\nINTENSIVE CARE TRAUMA\n\n\nTRAUMA\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-22 10:27:06\n\n\nTRAUMA\n\n\nINTENSIVE CARE TRAUMA\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-28 02:14:32\n\n\nINTENSIVE CARE TRAUMA\n\n\nINTENSIVE CARE TRAUMA\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-29 22:09:10\n\n\nINTENSIVE CARE TRAUMA\n\n\nNA\n\n\nIn our table we see some (preselected) rows and all of our columns. We’re looking at just 1 patient (ENCOUNTER_NUM_ANONYMIZED) with a snapshot of some of their events (EVENT_TS_FUZZED), which service they were coming from (FROM_SERVICE) and which service they were going to (TO_SERVICE).\nLet’s now take a look at the SPECIFIC_PROCEDURES data\n\n\nPROCEDURE_FILE_PATH <- here::here(\"_posts\",\"2022-08-12-putting-the-fun-in-funneljoin\", \"SPECIFIC_PROCEDURES.csv\")\nSPECIFIC_PROCEDURES <- read.csv(PROCEDURE_FILE_PATH,\n                                 stringsAsFactors = FALSE)\n\nSPECIFIC_PROCEDURES %>%\n  kableExtra::kbl() %>%\n  kableExtra::kable_styling() \n\n\n\nENCOUNTER_NUM_ANONYMIZED\n\n\nEVENT_TS_FUZZED\n\n\nFROM_SERVICE\n\n\nTO_SERVICE\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-22 10:27:06\n\n\nTRAUMA\n\n\nINTENSIVE CARE TRAUMA\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-22 21:34:13\n\n\nTRAUMA\n\n\nINTENSIVE CARE TRAUMA\n\n\n7cc7972a-58a1-4c78-a0dc-83021c6dc0c6\n\n\n2083-06-02 10:46:45\n\n\nTRAUMA\n\n\nINTENSIVE CARE TRAUMA\n\n\n7cc7972a-58a1-4c78-a0dc-83021c6dc0c6\n\n\n2083-06-22 02:59:57\n\n\nTRAUMA\n\n\nINTENSIVE CARE TRAUMA\n\n\n87d439b0-4f26-4b73-8df3-bf5dbbf34ca7\n\n\n2090-09-05 15:01:52\n\n\nNEUROSURGERY\n\n\nINTENSIVE CARE NEURO SURGERY\n\n\nWe’re showing all of SPECIFIC_PROCEDURES because it’s much smaller. It has the same structure as the ADT file (and that’s because the procedures are a subset of all the ADT events). Now that we see the procedures we can also see that it’s an event in ADT_EVENTS. The first SPECIFIC_PROCEDURE:\n\n\nSPECIFIC_PROCEDURES %>%\n  slice(1) %>%\n  kableExtra::kbl() %>%\n  kableExtra::kable_styling() \n\n\n\nENCOUNTER_NUM_ANONYMIZED\n\n\nEVENT_TS_FUZZED\n\n\nFROM_SERVICE\n\n\nTO_SERVICE\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-22 10:27:06\n\n\nTRAUMA\n\n\nINTENSIVE CARE TRAUMA\n\n\nand now the ADT events with the event before, the procedure event, and the event after (which is what we want to specifically identify; eventually that is).\n\n\nADT_EVENTS %>%\n  slice( c(15, 16, 17) ) %>%\n  kableExtra::kbl() %>%\n  kableExtra::kable_styling() \n\n\n\nENCOUNTER_NUM_ANONYMIZED\n\n\nEVENT_TS_FUZZED\n\n\nFROM_SERVICE\n\n\nTO_SERVICE\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-18 20:02:58\n\n\nTRAUMA\n\n\nTRAUMA\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-22 10:27:06\n\n\nTRAUMA\n\n\nINTENSIVE CARE TRAUMA\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-22 19:54:10\n\n\nINTENSIVE CARE TRAUMA\n\n\nTRAUMA\n\n\nA fun note before we move on: When you look at these data you’ll see some NA in there. Those NA are Rs NA which is effectively missing data. In this case NA is absolutely not NA which is sodium (sodium is not a service). You should really take a look at some of the “fun” with NA we’ve had.\nWhat we want and the behavior we’d expect\nOur task was to identify the event that happens after specific procedures. From the above, we can see an example of that:\n\n\nADT_EVENTS %>%\n  slice( c(16, 17) ) %>%\n  kableExtra::kbl() %>%\n  kableExtra::kable_styling() \n\n\n\nENCOUNTER_NUM_ANONYMIZED\n\n\nEVENT_TS_FUZZED\n\n\nFROM_SERVICE\n\n\nTO_SERVICE\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-22 10:27:06\n\n\nTRAUMA\n\n\nINTENSIVE CARE TRAUMA\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-22 19:54:10\n\n\nINTENSIVE CARE TRAUMA\n\n\nTRAUMA\n\n\nThe first row is the procedure and the second row is the event that happens after a specific procedure. At the end of what we do, we want all of those events after procedures because we needed to understand more about patient movements after procedures for some of our modelling.\nA journey to find and a journey through funneljoin\nGiven that we have two data sets and we know that we want to match on certain things (ENCOUNTER_NUM_ANONYMIZED) but conditional on subsequent time stamps (EVENT_TS_FUZZED), we probably have some sort of join problem.\nI spent a lot of time trying out a lot of the standard join and merge options we find in R: dplyr, base::merge, and even ventured off into the land of fuzzyjoin. I tried a lot of things and all of those things were wrong or overly complicated.\nSo instead of just writing some code to find the next line in the ADT events data after a matching line in the procedures data, I spent a few7 half days8 searching for a package that probably does the thing I’m looking for. It took me quite a while and a variety of search terms (e.g., “time series join,” “join events after,” “fuzzyjoin for time,” “why doesn’t this specific thing I want exist and why am I so bad at this?”) until I eventually found funneljoin9.\nThe funneljoin package includes a lot of join options for time series data. In particular after_join is when we’re looking for events in one data set that occur after events in another data set. That was exactly what I was looking for. Though after_join was the key to solving my problems, I still had a few more problems10 but did eventually figure it all out and it was magical. Let’s walk through three examples with these data and after_join to show where I failed and where I eventually succeeded.\nMy first failure\nI dove into after_join with, basically, the default parameters. So let’s break this down:\nx is our procedures data because that’s our reference point: we want ADT events after procedures\ny is our ADT data to get those events after procedures\nby_user is the column we use for identifiers (ENCOUNTER_NUM_ANONYMIZED); this is a very typical parameter to expect in join and merge, as we usually want to join data sets based on some identifier\nby_time is the column we use to find the events (EVENT_TS_FUZZED); this is how funneljoin makes use of time series data\nsuffix appends labels to the newly created columns after the join, respectively for x then y\nSeems straight forward enough! Let’s see what happens:\n\n\nlibrary(funneljoin)\n\njoin_attempt_one <- after_join(\n  x = SPECIFIC_PROCEDURES,\n  y = ADT_EVENTS,\n  by_user = \"ENCOUNTER_NUM_ANONYMIZED\",\n  by_time = \"EVENT_TS_FUZZED\",\n  suffix = c(\"_PROCEDURES\",\"_ADT\")\n)\n\nrmarkdown::paged_table(join_attempt_one)\n\n\n\n\n{\"columns\":[{\"label\":[\"ENCOUNTER_NUM_ANONYMIZED\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"EVENT_TS_FUZZED_PROCEDURES\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"FROM_SERVICE_PROCEDURES\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"TO_SERVICE_PROCEDURES\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"EVENT_TS_FUZZED_ADT\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"FROM_SERVICE_ADT\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"TO_SERVICE_ADT\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nErr… it sort of looks like nothing happens. Why is that? Well it’s because our resulting join is empty11\nMy second failure\nI clearly missed something12. On a closer look at the parameters, it seemed like I needed a couple of more to make things work. So I brought them in and tried:\nmode is inner which is a specific type of join which is basically the intersection\ntype here is one of many options on how to think about the join and we set it to first-firstafter\nBefore we dive into the updated code let’s pause for what type is and what first-firstafter means. Heavily borrowing from the funneljoin site:\nfirst-firstafter: Take the first x, then the first y after that. For example, we have the first procedure for the first patient in the procedures (x) data, and we want the first event from the ADT (y) data that occurs afterwards. We don’t want all afterward, we don’t want any before. Just the one! So let’s try it:\n\n\njoin_attempt_two <- after_join(\n  x = SPECIFIC_PROCEDURES,\n  y = ADT_EVENTS,\n  by_user = \"ENCOUNTER_NUM_ANONYMIZED\",\n  by_time = \"EVENT_TS_FUZZED\",\n  suffix = c(\"_PROCEDURES\",\"_ADT\"),\n  mode = \"inner\",\n  type = \"first-firstafter\"\n)\n\nrmarkdown::paged_table(join_attempt_two)\n\n\n\n\n{\"columns\":[{\"label\":[\"ENCOUNTER_NUM_ANONYMIZED\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"EVENT_TS_FUZZED_PROCEDURES\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"FROM_SERVICE_PROCEDURES\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"TO_SERVICE_PROCEDURES\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"EVENT_TS_FUZZED_ADT\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"FROM_SERVICE_ADT\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"TO_SERVICE_ADT\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"a4461971-22e1-46e1-8454-aa7fbce54205\",\"2\":\"2082-06-22 10:27:06\",\"3\":\"TRAUMA\",\"4\":\"INTENSIVE CARE TRAUMA\",\"5\":\"2082-06-22 10:27:06\",\"6\":\"TRAUMA\",\"7\":\"INTENSIVE CARE TRAUMA\"},{\"1\":\"7cc7972a-58a1-4c78-a0dc-83021c6dc0c6\",\"2\":\"2083-06-02 10:46:45\",\"3\":\"TRAUMA\",\"4\":\"INTENSIVE CARE TRAUMA\",\"5\":\"2083-06-02 10:46:45\",\"6\":\"TRAUMA\",\"7\":\"INTENSIVE CARE TRAUMA\"},{\"1\":\"87d439b0-4f26-4b73-8df3-bf5dbbf34ca7\",\"2\":\"2090-09-05 15:01:52\",\"3\":\"NEUROSURGERY\",\"4\":\"INTENSIVE CARE NEURO SURGERY\",\"5\":\"2090-09-05 15:01:52\",\"6\":\"NEUROSURGERY\",\"7\":\"INTENSIVE CARE NEURO SURGERY\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nThe above shows the whole table but let’s take a closer look at something…\n\n\nENCOUNTER_NUM_ANONYMIZED\n\n\nEVENT_TS_FUZZED_PROCEDURES\n\n\nEVENT_TS_FUZZED_ADT\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-22 10:27:06\n\n\n2082-06-22 10:27:06\n\n\n7cc7972a-58a1-4c78-a0dc-83021c6dc0c6\n\n\n2083-06-02 10:46:45\n\n\n2083-06-02 10:46:45\n\n\n87d439b0-4f26-4b73-8df3-bf5dbbf34ca7\n\n\n2090-09-05 15:01:52\n\n\n2090-09-05 15:01:52\n\n\nWell that didn’t quite work because it’s actually finding the same time stamped events. So we’re not yet finding the first event after but we’ve at least got something. So… what are we missing?\nA third successful attempt\nWhat we’re missing is the next event. Right now, we’re getting back the same event. Fortunately there’s a parameter for that:\nmin_gap allows us to specify how much time there must be in between the first-firstafter events. There are also two companion parameters to this: max_gap and gap_col which tell us, respectively, the maximum time between events and a column to include the gap in time itself. For fun, let’s also add in gap_col so we can see the amount of time between events.\n\n\njoin_attempt_three <- after_join(\n  x = SPECIFIC_PROCEDURES,\n  y = ADT_EVENTS,\n  by_user = \"ENCOUNTER_NUM_ANONYMIZED\",\n  by_time = \"EVENT_TS_FUZZED\",\n  suffix = c(\"_PROCEDURES\",\"_ADT\"),\n  mode = \"inner\",\n  type = \"first-firstafter\",\n  min_gap = base::as.difftime(1,units=\"secs\"),\n  gap_col = TRUE\n)\n\nrmarkdown::paged_table(join_attempt_three)\n\n\n\n\n{\"columns\":[{\"label\":[\"ENCOUNTER_NUM_ANONYMIZED\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"EVENT_TS_FUZZED_PROCEDURES\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"FROM_SERVICE_PROCEDURES\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"TO_SERVICE_PROCEDURES\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".gap\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"EVENT_TS_FUZZED_ADT\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"FROM_SERVICE_ADT\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"TO_SERVICE_ADT\"],\"name\":[8],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"a4461971-22e1-46e1-8454-aa7fbce54205\",\"2\":\"2082-06-22 10:27:06\",\"3\":\"TRAUMA\",\"4\":\"INTENSIVE CARE TRAUMA\",\"5\":\"34024\",\"6\":\"2082-06-22 19:54:10\",\"7\":\"INTENSIVE CARE TRAUMA\",\"8\":\"TRAUMA\"},{\"1\":\"7cc7972a-58a1-4c78-a0dc-83021c6dc0c6\",\"2\":\"2083-06-02 10:46:45\",\"3\":\"TRAUMA\",\"4\":\"INTENSIVE CARE TRAUMA\",\"5\":\"1222979\",\"6\":\"2083-06-16 14:29:44\",\"7\":\"INTENSIVE CARE TRAUMA\",\"8\":\"INTENSIVE CARE TRAUMA\"},{\"1\":\"87d439b0-4f26-4b73-8df3-bf5dbbf34ca7\",\"2\":\"2090-09-05 15:01:52\",\"3\":\"NEUROSURGERY\",\"4\":\"INTENSIVE CARE NEURO SURGERY\",\"5\":\"74931\",\"6\":\"2090-09-06 11:50:43\",\"7\":\"INTENSIVE CARE NEURO SURGERY\",\"8\":\"NEUROSURGERY\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nOh that looks like we did it! Let’s look at just the snapshot of encounter numbers and timestamps with the .gap column:\n\n\nENCOUNTER_NUM_ANONYMIZED\n\n\nEVENT_TS_FUZZED_PROCEDURES\n\n\nEVENT_TS_FUZZED_ADT\n\n\n.gap\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-22 10:27:06\n\n\n2082-06-22 19:54:10\n\n\n34024\n\n\n7cc7972a-58a1-4c78-a0dc-83021c6dc0c6\n\n\n2083-06-02 10:46:45\n\n\n2083-06-16 14:29:44\n\n\n1222979\n\n\n87d439b0-4f26-4b73-8df3-bf5dbbf34ca7\n\n\n2090-09-05 15:01:52\n\n\n2090-09-06 11:50:43\n\n\n74931\n\n\nOH I THINK WE REALLY DID DO IT. Let’s just take a quick look back at an earlier chunk of code and verify based on just the ADT file for just one example13\n\n\nADT_EVENTS %>%\n  slice( c(16, 17) ) %>%\n  kableExtra::kbl() %>%\n  kableExtra::kable_styling() \n\n\n\nENCOUNTER_NUM_ANONYMIZED\n\n\nEVENT_TS_FUZZED\n\n\nFROM_SERVICE\n\n\nTO_SERVICE\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-22 10:27:06\n\n\nTRAUMA\n\n\nINTENSIVE CARE TRAUMA\n\n\na4461971-22e1-46e1-8454-aa7fbce54205\n\n\n2082-06-22 19:54:10\n\n\nINTENSIVE CARE TRAUMA\n\n\nTRAUMA\n\n\nConclusions\nThe first conclusion is that funneljoin is awesome and the second conclusion is that I’m lazy. It is also a safe assumption to conclude that I’ve used an excessive amount of unnecessary footnotes14.\nWhen we look back at these data and the problem, we probably could have solved this with some dplyr::group_by at the encounter (ID) level, do some checks on the timestamps, and some stuff like that. But we had these two data sets—each used separately for different reasons in the same project—so why not make this easy and intuitive? That’s the major advantage of funneljoin here.\nMaybe the way I solved this problem with funneljoin could have been better15, but this was really useful for me. It was also a super useful exercise for us to find this package and start to understand it because we deal with a lot of time stamps. We often have frequent questions about order of events, or we have to pull multiple pieces of data together from a variety of source systems and ensure it’s all in the right order.\nAnd learning funneljoin was fun and you can tell because it’s literally in the name.\n\n\n\nPou-Prom, Chloé, Joshua Murray, Sebnem Kuzulugil, Muhammad Mamdani, and Amol Verma. n.d. “From Compute to Care: Lessons Learned from Deploying an Early Warning System into Clinical Practice.” Frontiers in Digital Health, 174. https://www.frontiersin.org/articles/10.3389/fdgth.2022.932123/abstract.\n\n\nVerma, Amol A., Joshua Murray, Russell Greiner, Joseph Paul Cohen, Kaveh G. Shojania, Marzyeh Ghassemi, Sharon E. Straus, Chloe Pou-Prom, and Muhammad Mamdani. 2021. “Implementing Machine Learning in Medicine.” CMAJ 193 (34): E1351–57. https://doi.org/10.1503/cmaj.202434.\n\n\n“helping” is generous: I mostly asked a million stupid questions and as we’ve seen, spent many days finding a package to do what I want instead of just doing it↩︎\nagain: not without asking a million stupid questions and getting back a million fantastic answers↩︎\nand very hacky↩︎\na ‘few’ is defined as a week and ‘half day’ is defined as ‘definitely more than half a day’↩︎\nand very hacky↩︎\na million stupid questions followed by a million stupid mistakes↩︎\nagain: not a few↩︎\nagain: definitely more than half days↩︎\nfound is a generous term, I more so stumbled across it with no recollection how I found it after a week↩︎\nDid I mention I’m bad at this?↩︎\nagain: I ain’t so good at this↩︎\nthis is a generous way of saying I didn’t read the documentation↩︎\nwe really should verify for all but have I mentioned I’m lazy?↩︎\nnot enough footnotes and they are totally necessary↩︎\nalmost certainly it could have been better↩︎\n",
    "preview": {},
    "last_modified": "2022-08-12T13:14:41-04:00",
    "input_file": "putting-the-fun-in-funneljoin.knit.md"
  },
  {
    "path": "posts/2022-08-02-posits-conf-time/",
    "title": "POS...IT's conf() time 🥁",
    "description": "Pause, it's time to write about RStudio conf(2022). [10 min read]",
    "author": [
      {
        "name": "Maitreyee Sidhaye",
        "url": {}
      },
      {
        "name": "Chloe Pou-Prom",
        "url": {}
      }
    ],
    "date": "2022-08-04",
    "categories": [
      "post-miscellaneous"
    ],
    "contents": "\n\nContents\n2 years before\n2 weeks before\nDuring\nDo not skip the keynotes!\nFocus on the content of the talk\nGet social!\nCreate a POSITive space\nThings no one will tell you…\n\n2 business days later\n2 months later…?\n\n2 years before\nPicture this. It’s January 2020, you’re in Toronto, it’s the middle of winter, you’re just back from vacation… and you’re suffering from FOMO1 because your teammates are in sunny San Francisco collecting hex stickers, taking selfies with Hadley, and having the time of their lives at rstudio::conf(2020).\nWe were jealous.\nFast-forward… and now WE are the ones living the dream! ✨\n\n\n\nFigure 1: Check out the view! Now we are the ones creating FOMO 😎\n\n\n\n2 weeks before\nThis was the first time for both of us and we wanted to be ready. Here’s how you can do it too!\nDownload the RStudio conf app and bookmark all the talks that interest you. We asked our teammates which topics would be most relevant for the team. We ended up with the following: data science for healthcare, working with Quarto, working with Python, putting things in deployment/production, enhancements to tidymodels, best practices, MLOps/DevOps, training/teaching.\nWatch old talks. These can all be found here.2\nReach out to people who will be attending. The motto for this year’s conference was “It’s always better when we’re together”. Keeping that in mind, we reached out to our awesome RStudio customer success rep and to friends we had met through the RStudio Community Meetup. It was great to see them in-person!\nMake a list of places you want to visit. We prepared our sight-seeing and food map.\nDuring\nDo not skip the keynotes!\nWe got to experience our very own Oprah moment during the first keynote when the Posit announcement was made. Below is a sensationalized retelling of what happened during the very first talk.\n\n\nHADLEY, shortly after making the Posit rebranding announcement: “Now some of you may be wondering… where are our new stickers?”\nHADLEY pauses and surveys the crowd with a mischievous look.\nHADLEY: Now, if you all take a look under your seat…\n\n\nIntense shuffling sounds can be heard as THE AUDIENCE begins to search under their seat. People gasp and laugh as they pull envelopes from under their seat. MAITREYEE and CHLOE take their envelopes and find two stickers!\n\n\n\nFigure 2: Sticker reveal!\n\n\n\n[LATER IN THE EVENING…]\n\n\nIn the interest of avoiding widespread panic we’re not moving away from hexagons for package stickers. posit isn’t a package so it gets a different shape #rstudioconf\n\n— Hadley Wickham (@hadleywickham) July 27, 2022\n\n\n\nFocus on the content of the talk\nWe didn’t need to take extensive notes during the talks, since materials are available online.\nRStudio cares about the quality of the presentations. All speakers received coaching and it paid off. All the talks were engaging, easy-to-follow, and easy-to-digest.\nGet social!\nThere were plenty of opportunities for socializing and networking.\nThe evening reception was a great place to meet people over drinks, music, and games.\nThe R-ladies Meetup allowed us to meet awesome women that work with R, grab some hex stickers, and pick up the Women in STEM card deck.\n\n\nHello from #RLadies at #RStudioConf!! 👋#RStudioConf2022 pic.twitter.com/G9gqxpdnw7\n\n— R-Ladies Global (@RLadiesGlobal) July 29, 2022\n\nThe Birds of a Feather groups provide an opportunity to meet people that work on the same problems or use the same tools as you. We attended the Healthcare Birds of a Feather group and got to meet plenty of data practitioners who offered us insights into how things work at other hospitals and health institutions.\nCreate a POSITive space\nRStudio is committed to keeping their events inclusive and welcoming, which is highlighted by the Pac-man rule. During the conference, their actions supported their words through the use of pronoun pins, a masking policy, the use of color-coded “social distance” pins3, and diversity scholarships.\nThings no one will tell you…\nGrab food from the dessert table before the main food table. We learned this the hard way. Desserts disappear as fast as holographic hex stickers.\nSpeaking of stickers… make sure to grab hex stickers for your teammates.\n\n\n\nFigure 3: Sharing the swag!\n\n\n\n2 business days later\nThese were our favorite talks:\nHello Quarto: Share • Collaborate • Teach • Reimagine by Mine Cetinkaya-Rundel & Julia Stewart Lowndes gave us a glimpse of all the awesome things we could do with Quarto. We were super excited after watching this. And it seems like the community is keen too, because there is already an Awesome List for Quarto!\nHow Anchorage Built Alaska’s Vaccine Finder with R by Ben Matheson detailed the amazing work that the Anchorage Innovation Team did to develop and deploy a mobile vaccine finder. During the talk, Ben highlighted the importance of building and rolling out a MVP (minimum viable product).\nIntroducing workboots: Generate prediction intervals from tidymodel workflows by Mark Rieke introduced us to an R package for generating bootstrap prediction intervals within a tidymodel workflow. For a field like healthcare where uncertainty is relevant, this will be useful for us to incorporate in our projects, most of which are built with the tidymodels workflow.\nWhat they forgot to teach you about industry transitions from academia (WTF AITA) by Travis Gerke offered some great advice on poeple searching for jobs. While this talk focused on those transitioning from academia to industry, the materials presented will be useful to many! Check out the cool website!\nA Journey to Data Science: Tools for Equity and Diversity in STEM by Ileana Fenwick highlighted open science tools and communities to further equity and diversity in STEM.\nBuilding a ggplot2 rollercoaster: Creating amazing 3D data visualizations in R by Tyler Morgan-Wall showcased some cool things that can be done with ggplot2. Check out this awesome video!!\n2 months later…?\nWe hope to achieve the following:\nCreate our own hex sticker!\nIntegrate Quarto into our workflows. We hope to move this blog to Quarto. This tutorial will be a great starting point.\nTry Python for Shiny. Our team has a mix of R and Python developers, some who have used Shiny and some who have not.\nCreate templates with consistent color schemes. This came up during many of the Quarto-related talks. A quick and easy way to make reporting easier is to use consistent branding.\nGive agency to newcomers during onboarding. This came up during many talks. The idea is to let newcomers contribute to the code on Day 1.\nShare learning materials. From Jeff Leek’s closing keynote: “Mentorship is a debt you don’t pay off, you pay it forward”. We want to share some of the cool work we do and resources/tutorials, what it’s like working as a data scientist in healthcare. This blog is a step towards that.\n\nFOMO = fear of missing out↩︎\nSome of our favorites: “Object of type ‘closure’ is not subsettable” by Jenny Bryan, “Open Source Software for Data Science” by JJ Allaire, “Deploying End-To-End Data Science with Shiny, Plumber, and Pins” by Alex Gold.↩︎\nThe available pins were: “Hugs okay”, “Handshakes or fist bumps”, “Elbows”, and “Please keep your distance”↩︎\n",
    "preview": "posts/2022-08-04-posits-conf-time/rstudio_wall.jpg",
    "last_modified": "2022-08-04T09:18:08-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-06-21-is-my-ai-discriminatory/",
    "title": "Is my AI Discriminatory?",
    "description": "A discussion about bias in healthcare AI, and building models with fairness and ethics in mind. [5 min read]",
    "author": [
      {
        "name": "Meggie Debnath",
        "url": {}
      }
    ],
    "date": "2022-06-21",
    "categories": [
      "post-journal-club",
      "bias-fairness-ethics"
    ],
    "contents": "\n\nContents\nBias is everywhere\nHealthcare data, like any data, is flawed\nBuilding fairer models\nTakeaways\nAdditional resources\n\nArtificial intelligence (AI) and machine learning (ML), in particular, are part of decision making across industries, the public sectors, and everywhere in between. From identifying fraudulent bank transactions to listing the shows and movies we’re most likely to enjoy, AI is deeply embedded within our everyday lives. Oftentimes the results or outputs of these decisions are relatively harmless. However, increasingly, machine learning models are trained on complex and sensitive data, and used as part of decision making processes for diagnosing diseases or making hiring decisions. While these models have the ability to transform and improve lives, sometimes the decisions made or informed by AI can have far-reaching consequences.\nAs a part of our team’s bi-weekly journal clubs, we talked about sources of bias for AI models, the potential consequences and harms they can create, and what we can do as data scientists within the healthcare space.\nBias is everywhere\nBias is a part of human nature, coming from the limited view of the world that any single person or group can achieve. Whether implicitly or explicitly, this bias gets captured within our institutions and by extension - the data that we record. It can be reflected and amplified by artificial intelligence models that are trained using this data. Generally, the bias encoded within AI tools result in the greatest harm toward disadvantaged groups and people, such as racial minorities.\n\n\n\nFigure 1: Different types of bias that can exist when training machine learning models source\n\n\n\nThere are a few different ways bias can affect the prediction or decision made by an algorithm (Norori et al. 2021):\nHuman bias: underlying bias within the data caused by societal inequities and biased human decision-making\nData-driven bias: when training data is not representative of the population in which the algorithm will be applied\nAlgorithmic bias: when model development or training methods result in biased outcomes\nBy the same token, harms as a result of biased AI can manifest in different ways:\nHarm of allocation: if people are denied opportunities or resources based on the decision of an AI. An example of this is Amazon’s resume screening tool that was biased against women because it was trained on data from the past 10 years, which was overwhelmingly male.\nHarm of quality-of-service: when an AI tool does not perform at the same level for one group as it does for another. An example of this may be voice assistants trained on predominantly male voices may have trouble recognizing the voices of women who use it.\nIn this way, AI can be a flawed reflection of our society and its systemic biases, and can become a “gatekeeper” for jobs, medical treatments, and opportunities.\nHealthcare data, like any data, is flawed\nWithin the context of healthcare services, it is especially important to consider the types of bias within our data, as decisions made with the support of AI have the ability to influence critical decisions such as which patients receive additional care, or what medication dosages are prescribed. As with many other industries, healthcare and medical data can be biased, incorrect, missing, and incomplete.\nEven without the presence of AI tools, healthcare data holds implicit bias. For example, when visiting the emergency department for abdominal pain, men wait an average of 49 minutes before receiving an analgesic, whereas women wait an average of 65 minutes (Chen et al. 2008). The COVID-19 pandemic has also highlighted many existing racial inequities in healthcare, with the morbidity and mortality rate being higher for Black Americans, Native Americans, Pacific Islanders, and Hispanic/Latino patients compared with White Americans (Gawthrop 2022).\nWhen machine learning models are trained using data that already contains historical and societal inequities, these patterns are learned by the model, and the biases can be amplified when making predictions for new patients. Models that are deployed with underlying biases can disadvantage the groups who were under or mis-represented within the training data. For example, algorithms trained to identify disease within chest radiograph images were found to have higher underdiagnosis rates for female patients, patients under 20 years old, Black patients, and Hispanic patients. In other words, the risk of being falsely predicted as “healthy” were higher for these groups of people, meaning their clinical treatment would have been delayed or missed entirely (Seyyed-Kalantari et al. 2021).\nBuilding fairer models\nWe know that our models can contain harmful biases. But what can we do as data scientists in the healthcare space to ensure our models benefit the most people, and don’t cause harm? This might be a daunting question, one that led to a lot more questions for our team:\nHow can we improve our development and monitoring processes to identify biases before they are deployed?\nShould we have a feedback loop to communicate data discrepancies and inform future data collection?\nHow can we better incorporate the patient experience and expertise?\nCan we incorporate recourse and contestability into our data science pipelines?\nBuilding fairer models is an iterative process, and one that requires more than one solution. Although not all are possible to implement everywhere, especially all at once, below are a few things our team is learning about and working on:\nUnderstanding sources and limitations of data. This involves thinking about where the data coming from and if there’s potential for any of the variables to be biased. For example, data containing a single variable “gender” with limited responses may actually be a mixture of sex or perceived gender, rather than reflecting a patient’s true gender identity.\nBuilding models with an interdisciplinary and diverse team. When developing any kind of AI tool for clinical deployment, we heavily collaborate with the clinician teams that are involved. In addition, our project teams consist of people with varied backgrounds, experiences, cultures, and training.\nEvaluating model performance across sub-groups and applying techniques for improving explainability. There are many tools and resources for evaluating model fairness and understanding how a model performs for subgroups. Tools such as InterpretML and modelStudio.\nCreating and following standards for data, processes, models, and reporting. Standardization of these elements of a data science project ensures that there are clear guidelines and expectations, consistency among and across projects, and benchmarks to evaluate quality.\nMonitoring data, model usage, and performance over time. Monitoring how our models are performing after deployment is important to ensure there hasn’t been any data drift or changes in the environment that may cause poor performance.\nLearning, discussing, and sharing. We believe it’s important to keep learning, discussing through things like journal clubs, and where possible, sharing our processes, code, research, and learnings.\nAI has countless potential benefits, especially within healthcare - to improve patient care, hospital efficiency, and support decision-making. Working to build fairer models will help improve trust among clinically deployed AI tools, and ensure that all groups of people can benefit from the decisions made and supported by AI.\nTakeaways\nHuman bias, data-driven bias, and algorithmic bias are common ways in which a model might perform poorly for some patient subgroups, causing denial of opportunities or reducing quality of service\nThere is no perfect data, but there are different ways to combat bias and build models that are useful and reduce harms\nSome techniques for building better and fairer models include understanding sources of bias, building models considering multiple perspectives, evaluating them for fairness and explainability, and monitoring after deployment\nAdditional resources\nBelow are the full list of topics and readings that we dove into for our journal club series on bias, fairness, and ethics in healthcare AI.\nTopic\nReading Materials\nIntroduction to Bias, Fairness, and Ethics in AI\nMedicine’s Machine Learning Problem\nIndigenous Data, Representing Race in AI, and Structural Racism in Healthcare\nStructural racism in precision medicine: leaving no one behind Racial Disparities and Mistrust in End-of-Life Care Dissecting racial bias in an algorithm used to manage the health of populations Racism and Health: Evidence and Needed Research The disturbing return of scientific racism\nMachine Learning Best Practices & Regulations\nFDA In Brief: FDA Collaborates with Health Canada and UK’s MHRA to Foster Good Machine Learning Practice Algorithmic Impact Assessment tool Suicide hotline shares data with for-profit spinoff, raising ethical questions Their Bionic Eyes are now Obsolete and Unsupported\nFailure modes and Equity Concerns in Medical Imaging Models\nReading Race: AI Recognizes Patient’s Racial Identity in Medical Images Under-diagnosis bias of artificial intelligence algorithms applied to chest radiographs in under-served patient populations Common pitfalls and recommendations for using machine learning to detect and prognosticate for COVID-19 using chest radiographs and CT scans\nBias and Assessing Model Fairness & Transparency\nMan is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings How to make sure your model is fair, accountable, and transparent AI FactSheets 360\nRepresenting Sex & Gender in AI and Healthcare Data\nTransgender-inclusive measures of sex/gender for population surveys: Mixed-methods evaluation and recommendations Sex and gender differences and biases in artificial intelligence for biomedicine and healthcare\n\n\n\nChen, Esther H., Frances S. Shofer, Anthony J. Dean, Judd E. Hollander, William G. Baxt, Jennifer L. Robey, Keara L. Sease, and Angela M. Mills. 2008. “Gender Disparity in Analgesic Treatment of Emergency Department Patients with Acute Abdominal Pain.” Academic Emergency Medicine 15 (5): 414–18. https://doi.org/10.1111/j.1553-2712.2008.00100.x.\n\n\nGawthrop, Elisabeth. 2022. “Color of Coronavirus: COVID-19 Deaths Analyzed by Race and Ethnicity.” APM Research Lab. https://www.apmresearchlab.org/covid/deaths-by-race.\n\n\nNorori, Natalia, Qiyang Hu, Florence Marcelle Aellen, Francesca Dalia Faraci, and Athina Tzovara. 2021. “Addressing Bias in Big Data and AI for Health Care: A Call for Open Science.” Patterns 2 (10): 100347. https://doi.org/10.1016/j.patter.2021.100347.\n\n\nSeyyed-Kalantari, Laleh, Haoran Zhang, Matthew B. A. McDermott, Irene Y. Chen, and Marzyeh Ghassemi. 2021. “Underdiagnosis Bias of Artificial Intelligence Algorithms Applied to Chest Radiographs in Under-Served Patient Populations.” Nature Medicine 27 (12): 2176–82. https://doi.org/10.1038/s41591-021-01595-0.\n\n\n\n\n",
    "preview": "posts/2022-06-21-is-my-ai-discriminatory/ai-biases.jpg",
    "last_modified": "2022-08-02T16:07:56-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-09-ooh-na-na-where-are-my-sodium-labs/",
    "title": "Ooh na na... where are my sodium labs?",
    "description": "The NA bug, or, what happens when the same word is used in different contexts. [5 min read]",
    "author": [
      {
        "name": "Chloe Pou-Prom",
        "url": {}
      }
    ],
    "date": "2022-05-09",
    "categories": [
      "language-R",
      "project-chartwatch",
      "post-miscellaneous"
    ],
    "contents": "\n\nContents\nSilent deployment\nMonitoring labs\nThe NA bug\nTakeaways\n\n\n\n\nSilent deployment\nOur team had been working actively on developing CHARTwatch, an early warning system for patients in general internal medicine at St. Michael’s Hospital. In November 2019 we were ready to move to a silent deployment phase, which means our entire pipeline was running (from data extraction to data processing to model prediction), but no outputs were going to the end-user.\nTypically, the goal of the silent deployment phase is to uncover unexpected behaviors with the data, system, or model. During model development and evaluation, we had only worked with historical extracts of the data. When moving from historical data to live data, there’s the risk of running into data issues (Cohen et al. 2021).\nThe data can be different due to external factors. For example, all of our models were trained on data prior to COVID-19, but shortly after the beginning of our silent deployment phase, we began to observe cases of COVID-19 in the hospital.\nThe data can be different due to data entry errors. For example, a body temperature could incorrectly be entered as 3700 °C instead of 37.00 °C.\nThe data can be different due to selection bias. For example, during training we excluded patients with really short and really long visits, as they were rare. However, we may encounter these kinds of visits in the live data.\nMonitoring labs\nWe had set up a monitoring dashboard to measure model inputs and model outputs. On close inspection, we made a discovery that was unquestionably odd… no sodium labs had been measured since we had moved to silent testing!\n\n\n\n{\"x\":{\"attrs\":{\"title\":\"Electrolyte counts\",\"labels\":[\"day\",\"CA\",\"CL\",\"GLPOC\",\"K\",\"NA.\"],\"retainDateWindow\":false,\"axes\":{\"x\":{\"pixelsPerLabel\":60,\"drawAxis\":true},\"y\":{\"drawAxis\":true}},\"stackedGraph\":true,\"fillGraph\":false,\"fillAlpha\":0.15,\"stepPlot\":false,\"drawPoints\":false,\"pointSize\":1,\"drawGapEdgePoints\":false,\"connectSeparatedPoints\":false,\"strokeWidth\":1,\"strokeBorderColor\":\"white\",\"colorValue\":0.5,\"colorSaturation\":1,\"includeZero\":false,\"drawAxesAtZero\":false,\"logscale\":false,\"axisTickSize\":3,\"axisLineColor\":\"black\",\"axisLineWidth\":0.3,\"axisLabelColor\":\"black\",\"axisLabelFontSize\":14,\"axisLabelWidth\":60,\"drawGrid\":true,\"gridLineWidth\":0.3,\"rightGap\":5,\"digitsAfterDecimal\":2,\"labelsKMB\":false,\"labelsKMG2\":false,\"labelsUTC\":false,\"maxNumberWidth\":6,\"animatedZooms\":false,\"mobileDisableYTouch\":true,\"disableZoom\":false,\"legend\":\"auto\",\"labelsDivWidth\":400,\"labelsShowZeroValues\":true,\"labelsSeparateLines\":false,\"hideOverlayOnMouseOut\":true},\"scale\":\"daily\",\"annotations\":[],\"shadings\":[],\"events\":[],\"format\":\"date\",\"data\":[[\"2019-11-19T00:00:00.000Z\",\"2019-11-20T00:00:00.000Z\",\"2019-11-21T00:00:00.000Z\",\"2019-11-22T00:00:00.000Z\",\"2019-11-23T00:00:00.000Z\",\"2019-11-24T00:00:00.000Z\",\"2019-11-25T00:00:00.000Z\",\"2019-11-26T00:00:00.000Z\",\"2019-11-27T00:00:00.000Z\",\"2019-11-28T00:00:00.000Z\",\"2019-11-29T00:00:00.000Z\",\"2019-11-30T00:00:00.000Z\",\"2019-12-01T00:00:00.000Z\",\"2019-12-02T00:00:00.000Z\",\"2019-12-03T00:00:00.000Z\",\"2019-12-04T00:00:00.000Z\",\"2019-12-05T00:00:00.000Z\",\"2019-12-06T00:00:00.000Z\",\"2019-12-07T00:00:00.000Z\",\"2019-12-08T00:00:00.000Z\",\"2019-12-09T00:00:00.000Z\",\"2019-12-10T00:00:00.000Z\",\"2019-12-11T00:00:00.000Z\",\"2019-12-12T00:00:00.000Z\",\"2019-12-13T00:00:00.000Z\",\"2019-12-14T00:00:00.000Z\",\"2019-12-15T00:00:00.000Z\",\"2019-12-16T00:00:00.000Z\",\"2019-12-17T00:00:00.000Z\",\"2019-12-18T00:00:00.000Z\",\"2019-12-19T00:00:00.000Z\"],[18,23,18,19,18,18,20,15,21,11,20,15,15,14,14,9,14,12,7,12,17,13,14,12,21,15,15,24,24,22,13],[51,53,70,64,58,51,62,62,58,57,61,53,60,72,57,62,58,44,38,40,60,48,47,43,65,52,52,56,51,61,66],[56,41,50,56,54,66,51,56,52,60,72,52,79,74,83,91,77,64,60,61,57,68,59,62,55,42,59,65,63,50,70],[51,52,70,63,58,52,62,61,59,57,60,51,60,72,55,62,57,43,37,40,60,47,47,42,64,51,52,54,53,61,65],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]],\"fixedtz\":false,\"tzone\":\"UTC\"},\"evals\":[],\"jsHooks\":[]}\nFigure 1: Daily counts of lab measurements: this includes counts for calcium (CA), chloride (CL), glucose (GLPOC), potassium (K), and sodium (NA).\n\n\n\nDid this make sense? NA! Sodium is measured in routinely ordered blood tests. It’ll usually get ordered alongside other tests (such as calcium, chloride, glucose, and potassium) as part of a basic metabolic panel. In Figure 1, we look at the daily counts of labs on units in which CHARTwatch was silently deployed. The other labs were regularly measured, but our pipeline had not detected a single sodium lab. There was NA way sodium would be missing!\nThe NA bug\nAfter hours of detective work, we found the issue:\nIn R, the programming language we used to develop CHARTwatch, the symbol NA stands for “not available” and is used to represent missing data.\nIn chemistry, Na is the symbol used to represent the chemical element of sodium.\n\n\n\n{\"x\":{\"attrs\":{\"title\":\"Electrolyte counts\",\"labels\":[\"day\",\"CA\",\"CL\",\"GLPOC\",\"K\",\"NA.\"],\"retainDateWindow\":false,\"axes\":{\"x\":{\"pixelsPerLabel\":60,\"drawAxis\":true},\"y\":{\"drawAxis\":true}},\"stackedGraph\":true,\"fillGraph\":false,\"fillAlpha\":0.15,\"stepPlot\":false,\"drawPoints\":false,\"pointSize\":1,\"drawGapEdgePoints\":false,\"connectSeparatedPoints\":false,\"strokeWidth\":1,\"strokeBorderColor\":\"white\",\"colorValue\":0.5,\"colorSaturation\":1,\"includeZero\":false,\"drawAxesAtZero\":false,\"logscale\":false,\"axisTickSize\":3,\"axisLineColor\":\"black\",\"axisLineWidth\":0.3,\"axisLabelColor\":\"black\",\"axisLabelFontSize\":14,\"axisLabelWidth\":60,\"drawGrid\":true,\"gridLineWidth\":0.3,\"rightGap\":5,\"digitsAfterDecimal\":2,\"labelsKMB\":false,\"labelsKMG2\":false,\"labelsUTC\":false,\"maxNumberWidth\":6,\"animatedZooms\":false,\"mobileDisableYTouch\":true,\"disableZoom\":false,\"legend\":\"auto\",\"labelsDivWidth\":400,\"labelsShowZeroValues\":true,\"labelsSeparateLines\":false,\"hideOverlayOnMouseOut\":true},\"scale\":\"daily\",\"annotations\":[],\"shadings\":[],\"events\":[],\"format\":\"date\",\"data\":[[\"2019-11-19T00:00:00.000Z\",\"2019-11-20T00:00:00.000Z\",\"2019-11-21T00:00:00.000Z\",\"2019-11-22T00:00:00.000Z\",\"2019-11-23T00:00:00.000Z\",\"2019-11-24T00:00:00.000Z\",\"2019-11-25T00:00:00.000Z\",\"2019-11-26T00:00:00.000Z\",\"2019-11-27T00:00:00.000Z\",\"2019-11-28T00:00:00.000Z\",\"2019-11-29T00:00:00.000Z\",\"2019-11-30T00:00:00.000Z\",\"2019-12-01T00:00:00.000Z\",\"2019-12-02T00:00:00.000Z\",\"2019-12-03T00:00:00.000Z\",\"2019-12-04T00:00:00.000Z\",\"2019-12-05T00:00:00.000Z\",\"2019-12-06T00:00:00.000Z\",\"2019-12-07T00:00:00.000Z\",\"2019-12-08T00:00:00.000Z\",\"2019-12-09T00:00:00.000Z\",\"2019-12-10T00:00:00.000Z\",\"2019-12-11T00:00:00.000Z\",\"2019-12-12T00:00:00.000Z\",\"2019-12-13T00:00:00.000Z\",\"2019-12-14T00:00:00.000Z\",\"2019-12-15T00:00:00.000Z\",\"2019-12-16T00:00:00.000Z\",\"2019-12-17T00:00:00.000Z\",\"2019-12-18T00:00:00.000Z\",\"2019-12-19T00:00:00.000Z\",\"2019-12-20T00:00:00.000Z\",\"2019-12-21T00:00:00.000Z\",\"2019-12-22T00:00:00.000Z\",\"2019-12-23T00:00:00.000Z\",\"2019-12-24T00:00:00.000Z\",\"2019-12-25T00:00:00.000Z\",\"2019-12-26T00:00:00.000Z\",\"2019-12-27T00:00:00.000Z\",\"2019-12-28T00:00:00.000Z\",\"2019-12-29T00:00:00.000Z\",\"2019-12-30T00:00:00.000Z\",\"2019-12-31T00:00:00.000Z\",\"2020-01-01T00:00:00.000Z\",\"2020-01-02T00:00:00.000Z\",\"2020-01-03T00:00:00.000Z\",\"2020-01-04T00:00:00.000Z\",\"2020-01-05T00:00:00.000Z\",\"2020-01-06T00:00:00.000Z\",\"2020-01-07T00:00:00.000Z\",\"2020-01-08T00:00:00.000Z\",\"2020-01-09T00:00:00.000Z\",\"2020-01-10T00:00:00.000Z\",\"2020-01-11T00:00:00.000Z\",\"2020-01-12T00:00:00.000Z\",\"2020-01-13T00:00:00.000Z\",\"2020-01-14T00:00:00.000Z\",\"2020-01-15T00:00:00.000Z\",\"2020-01-16T00:00:00.000Z\",\"2020-01-17T00:00:00.000Z\",\"2020-01-18T00:00:00.000Z\",\"2020-01-19T00:00:00.000Z\",\"2020-01-20T00:00:00.000Z\"],[18,23,18,19,18,18,20,15,21,11,20,15,15,14,14,9,14,12,7,12,17,13,14,12,21,15,15,24,24,22,13,24,23,17,30,32,25,20,29,16,20,20,16,18,23,21,23,26,21,16,17,14,15,14,16,16,21,22,19,24,25,23,33],[51,53,70,64,58,51,62,62,58,57,61,53,60,72,57,62,58,44,38,40,60,48,47,43,65,52,52,56,51,61,66,72,66,62,87,77,60,81,79,70,67,61,53,53,82,76,74,85,76,91,85,75,74,73,63,72,65,80,65,68,62,54,74],[56,41,50,56,54,66,51,56,52,60,72,52,79,74,83,91,77,64,60,61,57,68,59,62,55,42,59,65,63,50,70,68,69,82,90,82,80,84,70,87,98,67,62,64,113,100,87,105,75,91,109,120,109,92,82,91,65,79,69,58,48,58,62],[51,52,70,63,58,52,62,61,59,57,60,51,60,72,55,62,57,43,37,40,60,47,47,42,64,51,52,54,53,61,65,72,66,62,86,77,60,81,79,70,66,61,53,53,79,75,74,86,76,90,84,75,74,72,63,72,64,80,66,67,62,55,73],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,68,66,62,87,77,60,81,79,70,67,61,53,53,82,76,75,85,77,91,84,75,74,73,63,72,65,80,65,68,62,54,73]],\"fixedtz\":false,\"tzone\":\"UTC\"},\"evals\":[],\"jsHooks\":[]}\nFigure 2: Daily counts of lab measurements after fixing the NA bug\n\n\n\nDepending on the context, the symbol meant something different! Our data extraction pipeline was interpreting the chemical element Na as “not available!”\nThe fix was quite straightforward. We updated the parameters of one of our function calls to specify that \"\" (empty string) should be used to represent “not available,” instead of \"NA\". From the documentation of the RODBC package:\n\nna.strings: character string(s) to be mapped to NA when reading character data, default “NA”\n\nAfter deploying this fix, sodium counts were back to normal (as seen in Figure 2).\nWhile the fix was a simple one-line change, the problem we uncovered lead to plenty of follow-up questions!\nWere there other cases where the same symbol meant two different things based on the context?\nWhat does our electronic health record use to represent a missing value? Do they go with a number that’s biologically impossible? (e.g., a body temperature of -1000) Do they use a specific symbol/term? (e.g., “not measured,” “missing”)\nHow are these decisions made?\nRecently, there’s been a push for improvement in data quality standards, such as “Datasheets for Datasets” (Gebru et al. 2021) and the explosion of features stores, model stores, and evaluation stores1.\nTakeaways\nNA (sodium) ≠ NA (not available)\nSilent deployment is important.\nThorough metadata and data quality standards are important to mitigating these kinds of issues.\n\n\n\nCohen, Joseph Paul, Tianshi Cao, Joseph D. Viviano, Chin-Wei Huang, Michael Fralick, Marzyeh Ghassemi, Muhammad Mamdani, Russell Greiner, and Yoshua Bengio. 2021. “Problems in the Deployment of Machine-Learned Models in Health Care.” CMAJ 193 (35): E1391–94. https://doi.org/10.1503/cmaj.202066.\n\n\nGebru, Timnit, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé III, and Kate Crawford. 2021. “Datasheets for Datasets.” Communications of the ACM 64 (12): 86–92. http://arxiv.org/abs/1803.09010.\n\n\nWhat kind of “store” do we think is next? 🤔↩︎\n",
    "preview": "posts/2022-05-09-ooh-na-na-where-are-my-sodium-labs/preview.PNG",
    "last_modified": "2022-07-14T13:14:13-04:00",
    "input_file": {}
  }
]
