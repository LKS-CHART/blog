@misc{gawthrop_color_2022,
    title = {Color of {Coronavirus}: {COVID}-19 deaths analyzed by race and ethnicity},
    shorttitle = {Color of {Coronavirus}},
    url = {https://www.apmresearchlab.org/covid/deaths-by-race},
    abstract = {COVID-19 has claimed close to a million lives in the U.S. Our ongoing Color of Coronavirus project monitors how and where COVID-19 mortality is inequitably impacting certain communities â€” to guide policy and community responses. Relying on CDC data, we have documented the race and ethnicity for 99\%},
    language = {en-US},
    urldate = {2022-06-13},
    journal = {APM Research Lab},
    author = {Gawthrop, Elisabeth},
    month = may,
    year = {2022},
}

@article{chen_gender_2008,
    title = {Gender {Disparity} in {Analgesic} {Treatment} of {Emergency} {Department} {Patients} with {Acute} {Abdominal} {Pain}},
    volume = {15},
    issn = {10696563, 15532712},
    url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1553-2712.2008.00100.x},
    doi = {10.1111/j.1553-2712.2008.00100.x},
    language = {en},
    number = {5},
    urldate = {2022-06-13},
    journal = {Academic Emergency Medicine},
    author = {Chen, Esther H. and Shofer, Frances S. and Dean, Anthony J. and Hollander, Judd E. and Baxt, William G. and Robey, Jennifer L. and Sease, Keara L. and Mills, Angela M.},
    month = may,
    year = {2008},
    pages = {414--418},
}

@article{seyyed-kalantari_underdiagnosis_2021,
    title = {Underdiagnosis bias of artificial intelligence algorithms applied to chest radiographs in under-served patient populations},
    volume = {27},
    copyright = {2021 The Author(s)},
    issn = {1546-170X},
    url = {https://www.nature.com/articles/s41591-021-01595-0},
    doi = {10.1038/s41591-021-01595-0},
    abstract = {Artificial intelligence (AI) systems have increasingly achieved expert-level performance in medical imaging applications. However, there is growing concern that such AI systems may reflect and amplify human bias, and reduce the quality of their performance in historically under-served populations such as female patients, Black patients, or patients of low socioeconomic status. Such biases are especially troubling in the context of underdiagnosis, whereby the AI algorithm would inaccurately label an individual with a disease as healthy, potentially delaying access to care. Here, we examine algorithmic underdiagnosis in chest X-ray pathology classification across three large chest X-ray datasets, as well as one multi-source dataset. We find that classifiers produced using state-of-the-art computer vision techniques consistently and selectively underdiagnosed under-served patient populations and that the underdiagnosis rate was higher for intersectional under-served subpopulations, for example, Hispanic female patients. Deployment of AI systems using medical imaging for disease diagnosis with such biases risks exacerbation of existing care biases and can potentially lead to unequal access to medical treatment, thereby raising ethical concerns for the use of these models in the clinic.},
    language = {en},
    number = {12},
    urldate = {2022-06-13},
    journal = {Nature Medicine},
    author = {Seyyed-Kalantari, Laleh and Zhang, Haoran and McDermott, Matthew B. A. and Chen, Irene Y. and Ghassemi, Marzyeh},
    month = dec,
    year = {2021},
    keywords = {Machine learning, Medical imaging},
    pages = {2176--2182},
}

@misc{thomas_medicines_2021,
	title = {Medicine's {Machine} {Learning} {Problem}},
	url = {https://bostonreview.net/articles/rachel-thomas-medicines-machine-learning-problem/},
	abstract = {As Big Data tools reshape health care, biased datasets and unaccountable algorithms threaten to further disempower patients.},
	language = {en-US},
	urldate = {2022-06-13},
	journal = {Boston Review},
	author = {Thomas, Rachel},
	month = jan,
	year = {2021},
}
